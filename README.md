#Lab 1
##Part 1
###Libraries Used :
####NumPy:
A fundamental package for numerical computations in Python, useful for handling arrays, mathematical functions, and linear algebra operations.

####Pandas:
A powerful library for data manipulation and analysis, offering data structures and functions to work with structured data seamlessly.
Matplotlib & Seaborn: Visualization libraries that provide plotting capabilities to create insightful and customizable graphs.

####Scikit-learn:
A robust machine learning library in Python that includes tools for classification, regression, clustering, and model evaluation.

####TensorFlow / PyTorch: Frameworks widely used for developing and training machine learning and deep learning models, offering flexibility and performance optimizations.

###Objective :
The primary goal of this project is to gain hands-on experience with the PyTorch library to tackle classification and regression tasks by implementing Deep Neural Network
(DNN) or Multi-Layer Perceptron (MLP) architectures. This project is divided into two main parts, focusing on regression .


###Tasks and Methodology :

###Part One: Regression Analysis Using the provided New York Stock Exchange dataset (dataset link), the following steps were carried out:

####Exploratory Data Analysis (EDA):
Performed data cleaning, handling missing values, and visualized key features to understand patterns and trends in the dataset.

####Deep Neural Network Architecture:
Built a regression model using a Deep Neural Network (DNN) in PyTorch to predict target values. The model architecture was designed with hidden layers and activation
functions suitable for continuous data prediction.

####Hyperparameter Tuning with GridSearch:
Optimized hyperparameters, including learning rate, optimizer, epoch count, and model structure, using GridSearch from the scikit-learn library to improve model performance.
Training and Evaluation Visualization:

####plotted and analyzed two key graphs: Loss vs. Epochs and Accuracy vs. Epochs for both training and test data. Interpretation of these graphs was provided to understand
the model's learning behavior and generalization ability.

####Regularization Techniques:
Applied various regularization methods, such as dropout and weight decay, to the initial model to enhance performance and reduce overfitting. The results were compared to
the original model to evaluate the effectiveness of these techniques.
